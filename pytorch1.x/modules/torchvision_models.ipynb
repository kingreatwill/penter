{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "torchvision.datasets: 一些加载数据的函数及常用的数据集接口；\n",
    "torchvision.models: 包含常用的模型结构（含预训练模型），例如AlexNet、VGG、ResNet等；\n",
    "torchvision.transforms: 常用的图片变换，例如裁剪、旋转等；\n",
    "torchvision.utils: 其他的一些有用的方法。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://pytorch.org/vision/stable/models.html\n",
    "\n",
    "[CNN网络架构演进：从LeNet到DenseNet](https://www.cnblogs.com/skyfsm/p/8451834.html)\n",
    "\n",
    "开山之作LeNet 1998 -> 王者归来AlexNet 2012 -> 越走越深VGG 2014 -> 大浪推手GoogLeNet 2014 -> 里程碑式创新ResNet 2015 -> 继往开来DenseNet 2017\n",
    "\n",
    "-|最早公开日期|发表情况|作者团队|arxiv地址\n",
    "---|---|---|---|---\n",
    "SqueezeNet|2016.02|ICLR-2017|伯克利&斯坦福|https://arxiv.org/abs/1602.07360\n",
    "MobileNet|2016.04|CVPR-2017|Google|https://arxiv.org/abs/1704.04961\n",
    "ShuffleNet|2016.06|CVPR-2017|Face++|https://arxiv.org/abs/1707.01083\n",
    "Xception|2016.10|-|Google|https://arxiv.org/abs/1610.02357\n",
    "\n",
    "> 其中 ShuffleNet 论文中引用了 SqueezeNet；Xception 论文中引用了 MobileNet\n",
    "\n",
    "### AlexNet - CNN\n",
    "torchvision.models.AlexNet()\n",
    "AlexNet中包含了几个比较新的技术点，也首次在CNN中成功应用了ReLU、Dropout和LRN等技巧。同时AlexNet也使用了GPU进行运算加速。\n",
    "\n",
    "- 成功使用ReLU作为CNN的激活函数，并验证其效果在较深的网络超过了Sigmoid，成功解决了Sigmoid在网络较深时的梯度弥散问题。虽然ReLU激活函数在很久之前就被提出了，但是直到AlexNet的出现才将其发扬光大。\n",
    "- 训练时使用Dropout随机忽略一部分神经元，以避免模型过拟合。Dropout虽有单独的论文论述，但是AlexNet将其实用化，通过实践证实了它的效果。在AlexNet中主要是最后几个全连接层使用了Dropout。\n",
    "- 在CNN中使用重叠的最大池化。此前CNN中普遍使用平均池化，AlexNet全部使用最大池化，避免平均池化的模糊化效果。并且AlexNet中提出让步长比池化核的尺寸小，这样池化层的输出之间会有重叠和覆盖，提升了特征的丰富性。\n",
    "- 提出了LRN层，局部响应归一化层（Local Response Normalization），对局部神经元的活动创建竞争机制，使得其中响应比较大的值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力。\n",
    "- 使用CUDA加速深度卷积网络的训练，利用GPU强大的并行计算能力，处理神经网络训练时大量的矩阵运算。AlexNet使用了两块GTX 580 GPU进行训练，单个GTX 580只有3GB显存，这限制了可训练的网络的最大规模。因此作者将AlexNet分布在两个GPU上，在每个GPU的显存中储存一半的神经元的参数。因为GPU之间通信方便，可以互相访问显存，而不需要通过主机内存，所以同时使用多块GPU也是非常高效的。同时，AlexNet的设计让GPU之间的通信只在网络的某些层进行，控制了通信的性能损耗。 \n",
    "- 数据增强，随机地从256*256的原始图像中截取224*224大小的区域（以及水平翻转的镜像），相当于增加了2*(256-224)^2=2048倍的数据量。如果没有数据增强，仅靠原始的数据量，参数众多的CNN会陷入过拟合中，使用了数据增强后可以大大减轻过拟合，提升泛化能力。进行预测时，则是取图片的四个角加中间共5个位置，并进行左右翻转，一共获得10张图片，对他们进行预测并对10次结果求均值。同时，AlexNet论文中提到了会对图像的RGB数据进行PCA处理，并对主成分做一个标准差为0.1的高斯扰动，增加一些噪声，这个Trick可以让错误率再下降1%。\n",
    "\n",
    "### ResNet - CNN\n",
    "torchvision.models.ResNet()\n",
    "### VGG - CNN\n",
    "torchvision.models.VGG()\n",
    "### GoogLeNet - CNN\n",
    "torchvision.models.GoogLeNet()\n",
    "### DenseNet - CNN\n",
    "torchvision.models.DenseNet()\n",
    "\n",
    "\n",
    "### Inception3 - CNN\n",
    "torchvision.models.Inception3()\n",
    "### MNASNet - CNN\n",
    "torchvision.models.MNASNet()\n",
    "### MobileNetV2 - CNN\n",
    "torchvision.models.MobileNetV2()\n",
    "### ShuffleNetV2 - CNN\n",
    "torchvision.models.ShuffleNetV2()\n",
    "### SqueezeNet - CNN\n",
    "torchvision.models.SqueezeNet()\n",
    "\n",
    "\n",
    "\n",
    "## 预训练模型(Pretrained model)相关\n",
    "参数：pretrained=True\n",
    "\n",
    "一般情况下预训练模型都是大型模型，具备复杂的网络结构，众多的参数量，以及在足够大的数据集下进行训练而产生的模型.\n",
    " 在NLP领域，预训练模型往往是语言模型，因为语言模型的训练是无监督的，可以获得大规模语料，同时语言模型又是许多典型NLP任务的基础，如机器翻译，文本生成，阅读理解等，常见的预训练模型有BERT, GPT, roBERTa, transformer-XL等.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18()\n",
    "alexnet = models.alexnet()\n",
    "vgg16 = models.vgg16()\n",
    "squeezenet = models.squeezenet1_0()\n",
    "densenet = models.densenet161()\n",
    "inception = models.inception_v3()\n",
    "googlenet = models.googlenet()\n",
    "shufflenet = models.shufflenet_v2_x1_0()\n",
    "mobilenet_v2 = models.mobilenet_v2()\n",
    "# mobilenet_v3_large = models.mobilenet_v3_large()\n",
    "# mobilenet_v3_small = models.mobilenet_v3_small()\n",
    "resnext50_32x4d = models.resnext50_32x4d()\n",
    "wide_resnet50_2 = models.wide_resnet50_2()\n",
    "mnasnet = models.mnasnet1_0()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torchvision.models.resnet as resnet\n",
    "# 加载预训练模型\n",
    "resNet50 = models.resnet50(pretrained=True)\n",
    "ResNet50 = models.ResNet(resnet.Bottleneck, [3, 4, 6, 3], num_classes=2)\n",
    "\n",
    "# 读取参数\n",
    "pretrained_dict = resNet50.state_dict()\n",
    "model_dict = ResNet50.state_dict()\n",
    "\n",
    "# 将pretained_dict里不属于model_dict的键剔除掉\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "\n",
    "# 更新现有的model_dict\n",
    "model_dict.update(pretrained_dict)\n",
    "\n",
    "# 加载真正需要的state_dict\n",
    "ResNet50.load_state_dict(model_dict)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}