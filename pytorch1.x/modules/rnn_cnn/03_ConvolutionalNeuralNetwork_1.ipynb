{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 卷积神经网络（convolutional neural network）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch # 基础库\n",
    "from torch.utils.data import TensorDataset,DataLoader # 数据加载\n",
    "from torch import nn # 网络模型\n",
    "from torch.nn import init # 参数初始化\n",
    "import torch.optim as optim # 优化算法\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE' # plt绘图报错（不显示图的问题）\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus']=False #用来正常显示负号"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 计算准确率\n",
    "def evaluate_accuracy(test_data_iter, model):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for X, y in test_data_iter:\n",
    "        acc_sum += (model(X).argmax(dim=1) == y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# trainTransform = transforms.Compose([\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     normTransform\n",
    "# ])\n",
    "# testTransform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     normTransform\n",
    "# ])\n",
    "\n",
    "\n",
    "mnist_train = torchvision.datasets.FashionMNIST(root='F:/bigdata/ai/Pytorch_Datasets',\n",
    "                                                train=True,\n",
    "                                                download=True,\n",
    "                                                transform=transforms.Compose([transforms.ToTensor()]))\n",
    "mnist_test = torchvision.datasets.FashionMNIST(root='F:/bigdata/ai/Pytorch_Datasets',\n",
    "                                               train=False,\n",
    "                                               download=True,\n",
    "                                               transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "\n",
    "model = models.alexnet(num_classes = 10)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 58, 58])\n",
      "torch.Size([1, 1, 28, 28])\n",
      "torch.Size([1, 1, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "# AlexNet\n",
    "# -> 第一个卷积层nn.Conv2d(\n",
    "# in_channels=3,\n",
    "# out_channels=64,\n",
    "# kernel_size=11,\n",
    "# stride=4,\n",
    "# padding=2),\n",
    "# outsize = (w-kernel_size+2*padding)/stride  + 1\n",
    "# 那么input的size要是(in_channels, w,h)\n",
    "# 卷积层对于图像是没有尺寸限制要求的, 但是in_channels一定要一致\n",
    "\n",
    "img = torch.randn((1,1,300,300))\n",
    "filters = torch.randn(1, 1, 11, 11)\n",
    "o = nn.functional.conv2d(img,filters,stride=5,padding=0)\n",
    "print(o.size()) # conv2d是下界\n",
    "\n",
    "p = nn.functional.max_pool2d(o,kernel_size= 3,stride=2)\n",
    "print(p.size()) # conv2d是上界\n",
    "\n",
    "avp = nn.functional.adaptive_avg_pool2d(o,output_size= (8,8))\n",
    "print(avp.size()) # 指定输出output_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# print(mnist_test[0][0].size())\n",
    "# print(mnist_test[0][0].repeat(1,3, 3, 3).size())\n",
    "# print(mnist_test[0][0].repeat(1,3, 3, 3).flatten().size())\n",
    "# def show_fashion_mnist(images, labels):\n",
    "#     # 这里的_表示我们忽略（不使用）的变量\n",
    "#     _, figs = plt.subplots(1, len(images), figsize=(12, 12))\n",
    "#     for f, img, lbl in zip(figs, images, labels):\n",
    "#         f.imshow(img.view((84, 84)).numpy()) # img.view((84, 84)).numpy()\n",
    "#         f.set_title(lbl)\n",
    "#         f.axes.get_xaxis().set_visible(False)\n",
    "#         f.axes.get_yaxis().set_visible(False)\n",
    "#     plt.show()\n",
    "# show_fashion_mnist([mnist_test[0][0].repeat(1,1, 3, 3),mnist_test[1][0].repeat(1,1, 3, 3)], [mnist_test[0][1],mnist_test[1][1]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n",
      "torch.Size([10, 3, 28, 28])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-5-76cb0f65bce8>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     19\u001B[0m         \u001B[1;31m# 反向传播\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m# 梯度清零，等价于net.zero_grad()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m         \u001B[0ml\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0meval\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\ProgramData\\Anaconda3\\envs\\penter\\lib\\site-packages\\torch\\tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph)\u001B[0m\n\u001B[0;32m    183\u001B[0m                 \u001B[0mproducts\u001B[0m\u001B[1;33m.\u001B[0m \u001B[0mDefaults\u001B[0m \u001B[0mto\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;31m`\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;31m`\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    184\u001B[0m         \"\"\"\n\u001B[1;32m--> 185\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    186\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    187\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\ProgramData\\Anaconda3\\envs\\penter\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001B[0m\n\u001B[0;32m    123\u001B[0m         \u001B[0mretain_graph\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    124\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 125\u001B[1;33m     Variable._execution_engine.run_backward(\n\u001B[0m\u001B[0;32m    126\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    127\u001B[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(mnist_train, batch_size=batch_size,shuffle=True)\n",
    "test_dataloader = DataLoader(mnist_test, batch_size=batch_size)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    for X, y in train_dataloader:\n",
    "        # X.size()-> [1,1,28,28]\n",
    "        X = X.repeat(1,3, 1, 1) # X = X.repeat(1, 3, 3, 3)\n",
    "        print(X.size())\n",
    "        # 计算预测误差\n",
    "        output = model(X)\n",
    "        # y = torch.nn.functional.one_hot(y,10) # 不需要\n",
    "        l = loss(output, y)\n",
    "\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad() # 梯度清零，等价于net.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    print('epoch %d, loss: %f, acc: %f' % (epoch, l.item() , evaluate_accuracy(test_dataloader,model)))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    print(model(mnist_test[i][0]).argmax(dim=1) ,\"---实际：\", mnist_test[i][1] )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}