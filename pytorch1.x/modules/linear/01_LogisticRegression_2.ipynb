{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torchvision as tv\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 不是逻辑回归"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 超参数\n",
    "EPOCH = 5\n",
    "BATCH_SIZE = 100\n",
    "DOWNLOAD_MNIST = True   # 下过数据的话, 就可以设置成 False\n",
    "N_TEST_IMG = 10          # 到时候显示 5张图片看效果, 如上图一\n",
    "\n",
    "\n",
    "\n",
    "class DNN(t.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "\n",
    "        train_data = tv.datasets.FashionMNIST(\n",
    "        root=\"./fashionmnist/\",\n",
    "        train=True,\n",
    "        transform=tv.transforms.ToTensor(),\n",
    "        download=DOWNLOAD_MNIST\n",
    "        )\n",
    "\n",
    "        test_data = tv.datasets.FashionMNIST(\n",
    "        root=\"./fashionmnist/\",\n",
    "        train=False,\n",
    "        transform=tv.transforms.ToTensor(),\n",
    "        download=DOWNLOAD_MNIST\n",
    "        )\n",
    "\n",
    "        print(test_data)\n",
    "\n",
    "\n",
    "        # Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)\n",
    "        self.train_loader = t.utils.data.DataLoader(\n",
    "            dataset=train_data,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True)\n",
    "\n",
    "        self.test_loader = t.utils.data.DataLoader(\n",
    "            dataset=test_data,\n",
    "            batch_size=1000,\n",
    "            shuffle=True)\n",
    "\n",
    "        self.cnn = t.nn.Sequential(\n",
    "            t.nn.Conv2d(\n",
    "                in_channels=1,      # input height\n",
    "                out_channels=32,    # n_filters\n",
    "                kernel_size=5,      # filter size\n",
    "                stride=1,           # filter movement/step\n",
    "                padding=2,      # 如果想要 con2d 出来的图片长宽没有变化, padding=(kernel_size-1)/2 当 stride=1\n",
    "            ),                  # output shape (16, 28, 28)\n",
    "            t.nn.ELU(),    # activation\n",
    "            t.nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            t.nn.Conv2d(\n",
    "                in_channels=32,      # input height\n",
    "                out_channels=64,    # n_filters\n",
    "                kernel_size=3,      # filter size\n",
    "                stride=1,           # filter movement/step\n",
    "                padding=1,      # 如果想要 con2d 出来的图片长宽没有变化, padding=(kernel_size-1)/2 当 stride=1\n",
    "            ),                  # output shape (64, 14, 14)\n",
    "            t.nn.ELU(),    # activation\n",
    "            t.nn.MaxPool2d(kernel_size=2)  # output shape (64, 7, 7)\n",
    "        )\n",
    "\n",
    "        self.dnn = t.nn.Sequential(\n",
    "            t.nn.Linear(7*7*64,256),\n",
    "            t.nn.Dropout(0.5),\n",
    "            t.nn.ELU(),\n",
    "            t.nn.Linear(256,10),\n",
    "        )\n",
    "\n",
    "        self.lr = 0.001\n",
    "        self.loss = t.nn.CrossEntropyLoss()\n",
    "        self.opt = t.optim.Adam(self.parameters(), lr = self.lr)\n",
    "\n",
    "    def forward(self,x):\n",
    "        cnn1 = self.cnn(x)\n",
    "        #print(cnn1.shape)\n",
    "        cnn1 = cnn1.view(-1,7*7*64)\n",
    "        #print(cnn1.shape)\n",
    "        out = self.dnn(cnn1)\n",
    "        #print(out.shape)\n",
    "        return(out)\n",
    "\n",
    "def train():\n",
    "    use_gpu =  t.cuda.is_available()\n",
    "    model = DNN()\n",
    "    if(use_gpu):\n",
    "        model.cuda()\n",
    "    print(model)\n",
    "    loss = model.loss\n",
    "    opt = model.opt\n",
    "    dataloader = model.train_loader\n",
    "    testloader = model.test_loader\n",
    "\n",
    "\n",
    "    for e in range(EPOCH):\n",
    "        step = 0\n",
    "        ts = time.time()\n",
    "        for (x, y) in (dataloader):\n",
    "\n",
    "\n",
    "            model.train()# train model dropout used\n",
    "            step += 1\n",
    "            b_x = x.view(-1,1,28,28)   # batch x, shape (batch, 28*28)\n",
    "            #print(b_x.shape)\n",
    "            b_y = y\n",
    "            if(use_gpu):\n",
    "                b_x = b_x.cuda()\n",
    "                b_y = b_y.cuda()\n",
    "            out = model(b_x)\n",
    "            losses = loss(out,b_y)\n",
    "            opt.zero_grad()\n",
    "            losses.backward()\n",
    "            opt.step()\n",
    "            if(step%100 == 0):\n",
    "                if(use_gpu):\n",
    "                    print(e,step,losses.data.cpu().numpy())\n",
    "                else:\n",
    "                    print(e,step,losses.data.numpy())\n",
    "\n",
    "                model.eval() # train model dropout not use\n",
    "                for (tx,ty) in testloader:\n",
    "                    t_x = tx.view(-1,1, 28,28)   # batch x, shape (batch, 28*28)\n",
    "                    t_y = ty\n",
    "                    if(use_gpu):\n",
    "                        t_x = t_x.cuda()\n",
    "                        t_y = t_y.cuda()\n",
    "                    t_out = model(t_x)\n",
    "                    if(use_gpu):\n",
    "                        acc = (np.argmax(t_out.data.cpu().numpy(),axis=1) == t_y.data.cpu().numpy())\n",
    "                    else:\n",
    "                        acc = (np.argmax(t_out.data.numpy(),axis=1) == t_y.data.numpy())\n",
    "\n",
    "                    print(time.time() - ts ,np.sum(acc)/1000)\n",
    "                    ts = time.time()\n",
    "                    break#只测试前1000个\n",
    "\n",
    "\n",
    "\n",
    "    t.save(model, './model.pkl')  # 保存整个网络\n",
    "    t.save(model.state_dict(), './model_params.pkl')   # 只保存网络中的参数 (速度快, 占内存少)\n",
    "    #加载参数的方式\n",
    "    \"\"\"net = DNN()\n",
    "    net.load_state_dict(t.load('./model_params.pkl'))\n",
    "    net.eval()\"\"\"\n",
    "    #加载整个模型的方式\n",
    "    net = t.load('./model.pkl')\n",
    "    net.cpu()\n",
    "    net.eval()\n",
    "    for (tx,ty) in testloader:\n",
    "        t_x = tx.view(-1, 1,28,28)   # batch x, shape (batch, 28*28)\n",
    "        t_y = ty\n",
    "\n",
    "        t_out = net(t_x)\n",
    "        #acc = (np.argmax(t_out.data.CPU().numpy(),axis=1) == t_y.data.CPU().numpy())\n",
    "        acc = (np.argmax(t_out.data.numpy(),axis=1) == t_y.data.numpy())\n",
    "\n",
    "        print(np.sum(acc)/1000)\n",
    "\n",
    "train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}